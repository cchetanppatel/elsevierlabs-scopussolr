# KinesisConnector Application Settings
appName = kinesisToRedshiftBasic
retryLimit = 3
# 1MB = 1024*1024 = 1048756
bufferSizeByteLimit = 1024 
#bufferRecordCountLimit = 25
bufferRecordCountLimit = 3

# Redshift parameters for KinesisConnector
redshiftDataTable = kinesisBasicTable
redshiftEndpoint = https\://redshift.us-east-1.amazonaws.com
#redshiftEndpoint = https://redshift.us-east-1.amazonaws.com
#redshiftUsername = USERNAME
redshiftUsername = darin
#redshiftPassword = PASSWORD
redshiftPassword = Mcbeath65
# URL is optional if automatically creating the cluster
#redshiftURL = URL
redshiftDataDelimiter = |


# Optional Redshift parameters for automatically creating the cluster
#createRedshiftCluster = false
createRedshiftCluster = true
redshiftClusterIdentifier = kinesisCluster
#redshiftDatabaseName = kinesisDatabase
redshiftDatabaseName = kinesisdatabase
# dw.hs1.xlarge or dw.hs1.8xlarge
redshiftClusterType = dw.hs1.xlarge
redshiftNumberOfNodes = 2

# Optional Redshift parameters for automatically creating the data table
#createRedshiftDataTable = false
createRedshiftDataTable = true

# S3 parameters for KinesisConnector
s3Bucket = scopus-kinesis-bucket
s3Endpoint = https\://s3.amazonaws.com

# Optional S3 parameters for automatically creating the bucket
#createS3Bucket = false
createS3Bucket = true

# Kinesis parameters for KinesisConnector
kinesisEndpoint = https\://kinesis.us-east-1.amazonaws.com
#kinesisInputStream = redshiftStream
kinesisInputStream = scopus-eid-affilid

# Optional Kinesis parameters for automatically creating the stream
createKinesisInputStream = false
createKinesisOutputStream = false
kinesisInputStreamShardCount = 2
kinesisOutputStreamShardCount = 2

# Specifies the input file from which the StreamSource will read records
#createStreamSource = true
createStreamSource = false
inputStreamFile = users.txt